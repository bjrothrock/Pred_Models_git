p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
# Create a shareable link to your chart
# Set up API credentials: https://plot.ly/r/getting-started
chart_link = plotly_POST(p, filename="scatter3d/basic")
chart_link
library(plotly)
library(dplyr)
df <- read.csv('https://raw.githubusercontent.com/plotly/datasets/master/1962_2006_walmart_store_openings.csv')
View(df)
g <- list(
scope = 'usa',
showland = T,
landcolor = toRGB("gray90"),
showcountries = F,
subunitcolor = toRGB("white")
)
one_map <- function(dat) {
plot_geo(dat) %>%
add_markers(x = ~LON, y = ~LAT, color = I("blue"), alpha = 0.5) %>%
add_text(x = -78, y = 47, text = ~unique(YEAR), color = I("black")) %>%
layout(geo = g)
}
p <- df %>%
group_by(YEAR) %>%
do(map = one_map(.)) %>%
subplot(nrows = 9) %>%
layout(
showlegend = FALSE,
title = 'New Walmart Stores per year 1962-2006<br> Source: <a href="http://www.econ.umn.edu/~holmes/data/WalMart/index.html">University of Minnesota</a>',
width = 1000,
height = 900,
hovermode = FALSE
)
chart_link = plotly_POST(p, filename="maps/small-multiple")
chart_link
plot_ly(z=volcano,type = 'heatmap')
install.packages("googleVis")
library(googleVis)
demo(WorldBank) ## At least version googleVis_0.2.10 required
library(googleVis)
Gauge <-  gvisGauge(CityPopularity,
options=list(min=0, max=800, greenFrom=500,
greenTo=800, yellowFrom=300, yellowTo=500,
redFrom=0, redTo=300, width=400, height=300))
plot(Gauge)
Tree <- gvisTreeMap(Regions,
"Region", "Parent",
"Val", "Fac",
options=list(fontSize=16))
plot(Tree)
Cal <- gvisCalendar(Cairo,
datevar="Date",
numvar="Temp",
options=list(
title="Daily temperature in Cairo",
height=320,
calendar="{yearLabel: { fontName: 'Times-Roman',
fontSize: 32, color: '#1A8763', bold: true},
cellSize: 10,
cellColor: { stroke: 'red', strokeOpacity: 0.2 },
focusedCellColor: {stroke:'red'}}")
)
plot(Cal)
library(ggmap)
install.packages("ggmap")
library(ggmap)
qmap('Liverpool')
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
install.packages("ggmap")
library(ggmap)
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
install.packages('dplyr')
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
# rank violent crimes
violent_crimes$offense <- factor(
violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder")
)
# restrict to downtown
violent_crimes <- filter(violent_crimes,
-95.39681 <= lon & lon <= -95.34188,
29.73631 <= lat & lat <=  29.78400
)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite", color = I("red"))
library(ggmap)
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
# rank violent crimes
violent_crimes$offense <- factor(
violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder")
)
# restrict to downtown
violent_crimes <- filter(violent_crimes,
-95.39681 <= lon & lon <= -95.34188,
29.73631 <= lat & lat <=  29.78400
)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite", color = I("red"))
devtools::install_github("dkahle/ggmap")
devtools::install_github("hadley/ggplot2")
library(ggmap)
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
devtools::install_github("hadley/ggplot2")
devtools::install_github("hadley/ggplot2", force=TRUE)
library(ggmap)
library(ggplot2)
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
install.packages("ggmap")
install.packages("ggmap")
library(ggmap)
library(ggplot2)
qmap(location = "boston university")
install_github("dkahle/ggmap")
#--Define data file directory:
dir <- "http://www.sr.bham.ac.uk/~ajrs/papers/sanderson06"
#--Read in table of data (from Sanderson et al. 2006):
# This refers to a sample of 20 clusters of galaxies with Chandra X-ray data
CC <- read.table(paste(dir, "mean_Tprofile-CC.txt", sep="/"), header=TRUE)
nCC <- read.table(paste(dir, "mean_Tprofile-nCC.txt", sep="/"), header=TRUE)
#--Load extra library:
## if not already installed, then run:
# install.packages("ggplot2")
require(ggplot2)
#--Combine datasets into a single data frame:
CC$type <- "Cool core"
nCC$type <- "Non-cool core"
A <- rbind(CC, nCC)
#--Define axis labels:
xlabel <- as.expression(expression( paste("Radius (", R[500], ")") ))
ylabel <- "Scaled Temperature"
p <- ggplot(data=A, aes(x=r.r500, y=sckT, ymin=sckT.lo, ymax=sckT.up, fill=type, linetype=type)) +
geom_line() +
geom_ribbon(alpha=0.5) +
scale_x_log10() +
scale_y_log10() +
xlab(xlabel) +
ylab(ylabel)
ggsave(p, file="CC-vs_nCC_kT_prof.pdf", width=8, height=4.5)
plot(p)
library(ggmap)
qmap(location = "boston university")
install.packages("ggrepel")
library(ggmap)
library(ggplot2)
qmap(location = "boston university")
library("ggrepel", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
devtools::install_github('hadley/ggplot2')
devtools::install_github('thomasp85/ggforce')
devtools::install_github('thomasp85/ggraph')
devtools::install_github('slowkow/ggrepel')
library("ggraph", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
2+2
x<=2+2
x<-2+2
x
y<-rnorm(100)
y
plot(y)
hist(y)
z<-rexp(100)
z
scatter(x,z)
plot(x,z)
plot(y,z)
devtools::install_github('hadley/ggplot2')
qmap(location = "boston university")
library("ggforce", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggraph", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggrepel", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
devtools::install_github('hadley/ggplot2', force=TRUE)
devtools::install_github('thomasp85/ggforce',force=TRUE)
qmap(location = "baylor university")
devtools::install_github("dkahle/ggmap")
qmap(location = "boston university")
qmap(location = "baylor university")
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
detach("package:ggmap", unload=TRUE)
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
devtools::install_github("dkahle/ggmap",force=TRUE)
devtools::install_github('hadley/ggplot2', force=TRUE)
devtools::install_github('thomasp85/ggforce',force=TRUE)
devtools::install_github('thomasp85/ggraph',force=TRUE)
devtools::install_github('slowkow/ggrepel',force=TRUE)
detach("package:ggforce", unload=TRUE)
detach("package:ggmap", unload=TRUE)
detach("package:ggplot2", unload=TRUE)
detach("package:ggraph", unload=TRUE)
detach("package:ggrepel", unload=TRUE)
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggraph", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggrepel", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
get_googlemap("waco texas", zoom = 12, maptype = "hybrid") %>% ggmap()
install.packages("RgoogleMaps")
library("RgoogleMaps", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
bb <- qbbox(c(40.702147,40.711614,40.718217),
+   c(-74.015794,-74.012318,-73.998284), TYPE = "all",
+   margin = list(m=rep(5,4), TYPE = c("perc", "abs")[1]));
bb <- qbbox(c(40.702147,40.711614,40.718217),
c(-74.015794,-74.012318,-73.998284), TYPE = "all",
margin = list(m=rep(5,4), TYPE = c("perc", "abs")[1]));
map2= GetMap.bbox(bb$lonR, bb$latR,destfile = "MyTile3.png",
maptype = "satellite", size=c(640,640))
PlotOnStaticMap(map2)
lat = c(40.702147,40.718217,40.711614);
lon = c(-74.012318,-74.015794,-73.998284);
center = c(mean(lat), mean(lon));
zoom <- min(MaxZoom(range(lat), range(lon)));
markers = paste0("&markers=color:blue|label:S|40.714511,-74.009684&markers=color:", "green|label:G|40.714511,-74.009684&markers=color:red|color:red|")
ClubMap <- GetMap(center=center, zoom=zoom,markers=markers,destfile = "Dolls.png");
PlotOnStaticMap(ClubMap)
devtools::install_github("dkahle/ggmap",force=TRUE)
install_github("hadley/ggplot2@v2.2.0", force=TRUE)
devtools::install_github("hadley/ggplot2@v2.2.0", force=TRUE)
devtools::install_github('thomasp85/ggraph',force=TRUE)
devtools::install_github('slowkow/ggrepel',force=TRUE)
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggraph", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggrepel", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
qmap(location = "boston university")
detach("package:ggmap", unload=TRUE)
detach("package:ggplot2", unload=TRUE)
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
detach("package:ggmap", unload=TRUE)
detach("package:ggraph", unload=TRUE)
detach("package:ggrepel", unload=TRUE)
library('ggmap')
library('ggplot2')
library('ggraph')
library('ggrepel')
library('ggplot2')
library('ggplot')
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("ggplot2")
qmap(location = "baylor university")
get_googlemap("waco texas", zoom = 12, maptype = "hybrid") %>% ggmap()
qmap(location = "boston university",zoom = 12)
qmap(location = "boston university",zoom = 30)
qmap(location = "boston university",zoom = 25)
qmap(location = "boston university",zoom = 20)
qmap(location = "boston university",zoom = 15)
qmap(location = "boston university",zoom = 16)
qmap(location = "boston university",zoom = 17)
qmap(location = "baylor university")
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
library(dplyr)
crime
violent_crimes <- filter(crime,
offense != "auto theft", offense != "theft", offense != "burglary"
)
violent_crimes$offense <- factor(
violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder")
)
violent_crimes <- filter(violent_crimes,
-95.39681 <= lon & lon <= -95.34188,
29.73631 <= lat & lat <=  29.78400
)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite", color = I("red"))
robberies <- violent_crimes %>% filter(offense == "robbery")
qmplot(lon, lat, data = violent_crimes, geom = "blank", zoom = 15, maptype = "toner-background", darken = .7, legend = "topleft") +
stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = .3, color = NA) +
scale_fill_gradient2("Robbery\nPropensity", low = "white", mid = "yellow", high = "red", midpoint = 650)
qmplot(lon, lat, data = violent_crimes, maptype = "toner-background", color = offense) +
facet_wrap(~ offense)
qmap(location = "Rockhurst university")
qmap(location = "boston university",zoom = 17, maptype = "hybrid")
qmap(location = "12710 S. Hagan, 66062",zoom = 17, maptype = "hybrid")
qmap(location = "12710 S. Hagan, 66062",zoom = 20, maptype = "hybrid")
View(robberies)
install.packages("gcookbook")
library(gcookbook) # For the data set
library(igraph)
#look at the data
madmen2
g <- graph.data.frame(madmen2, directed=TRUE)
par(mar=c(0,0,0,0))
plot(g, layout=layout.fruchterman.reingold, vertex.size=8, edge.arrow.size=0.5,
vertex.label=NA)
library(igraph)
library(gcookbook) # For the data set
# Copy madmen and drop every other row
m <- madmen[1:nrow(madmen) %% 2 == 1, ]
g <- graph.data.frame(m, directed=FALSE)
V(g)$name
plot(g, layout=layout.fruchterman.reingold,  #l.f.r is a popular SN algorythym
vertex.size        = 4,          # Smaller nodes
vertex.label       = V(g)$name,  # Set the labels
vertex.label.cex   = 0.8,        # Slightly smaller font
vertex.label.dist  = 0.4,        # Offset the labels
vertex.label.color = "black")
g$layout <- layout.fruchterman.reingold  #l.f.r is a popular SN algorythym
plot(g)
E(g)
# Set some of the labels to "M"
E(g)[c(2,11,19)]$label <- "M"
# Set color of all to grey, and then color a few red
E(g)$color             <- "grey70"
E(g)[c(2,11,19)]$color <- "red"
plot(g)
install.packages('network')
library(network)
nodeinfo <- read.table("http://www.stat.psu.edu/~dhunter/Rnetworks/nodal.attr.txt", head=T)
myedges <- read.table("http://www.stat.psu.edu/~dhunter/Rnetworks/edgelist.txt")
diseasenw <- network(myedges, directed=F, bipartite=132,
vertex.attr = nodeinfo)
plot(diseasenw, vertex.col=3-nodeinfo$race,
vertex.sides=2+nodeinfo$sex,
main="Squares are female; triangles are male")
data(flo)
nflo<-network(flo)
plot(nflo, displaylabels=TRUE,vertex.cex=apply(flo,2,sum)+1, usearrows=FALSE,
vertex.sides=3+apply(flo,2,sum),
vertex.col=2+(network.vertex.names(nflo)=="Medici"))
install.packages("devtools")
require(devtools)
install.packages("choroplethr")
api.key.install(key="2e254c3c4a1ad6fe3322b0a267446163148e7a78")
choroplethr_acs(tableId="B19301", lod="state")
nba <- read.csv("http://datasets.flowingdata.com/ppg2008.csv", sep=",")
View(nba)
nba <- nba[order(nba$PTS),]
row.names(nba) <- nba$Name
nba <- nba[,2:20]
nba_matrix <- data.matrix(nba)
nba_heatmap <- heatmap(nba_matrix, Rowv=NA, Colv=NA, col = cm.colors(256), scale="column", margins=c(5,10))
playerID <- 201939
shotURL <- paste("http://stats.nba.com/stats/shotchartdetail?CFID=33&CFPARAMS=2014-15&ContextFilter=&ContextMeasure=FGA&DateFrom=&DateTo=&GameID=&GameSegment=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerID=",playerID,"&PlusMinus=N&Position=&Rank=N&RookieYear=&Season=2014-15&SeasonSegment=&SeasonType=Regular+Season&TeamID=0&VsConference=&VsDivision=&mode=Advanced&showDetails=0&showShots=1&showZones=0", sep = "")
shotData <- fromJSON(file = shotURL, method="C")
install.packages("rjson")
library(rjson)
playerID <- 201939
shotURL <- paste("http://stats.nba.com/stats/shotchartdetail?CFID=33&CFPARAMS=2014-15&ContextFilter=&ContextMeasure=FGA&DateFrom=&DateTo=&GameID=&GameSegment=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PaceAdjust=N&PerMode=PerGame&Period=0&PlayerID=",playerID,"&PlusMinus=N&Position=&Rank=N&RookieYear=&Season=2014-15&SeasonSegment=&SeasonType=Regular+Season&TeamID=0&VsConference=&VsDivision=&mode=Advanced&showDetails=0&showShots=1&showZones=0", sep = "")
shotData <- fromJSON(file = shotURL, method="C")
install.packages(c("choroplethr", "choroplethrAdmin1"))
library(choroplethr)
library(choroplethrAdmin1)
data(df_japan_census)
View(df_japan_census)
head(df_japan_census)
df_japan_census$value = df_japan_census$pop_density_km2_2010
admin1_choropleth("japan", df_japan_census)
admin1_choropleth("japan", df_japan_census, num_colors=1, reference_map=TRUE)
data(df_pop_county)
county_choropleth(df_pop_county,
title      = "US 2012 County Population Estimates",
legend     = "Population",
num_colors = 1,
state_zoom = c("california", "oregon", "washington"))
install.packages(c("choroplethr", "choroplethrAdmin1", "choroplethrMaps"))
install.packages(c("choroplethr", "choroplethrAdmin1", "choroplethrMaps"))
library("choroplethr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("choroplethrAdmin1", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("choroplethrMaps", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
data(df_pop_county)
county_choropleth(df_pop_county,
title      = "US 2012 County Population Estimates",
legend     = "Population",
num_colors = 1,
state_zoom = c("california", "oregon", "washington"))
data(state)
state77 <- as.data.frame(state.x77)
names(state77)[4] <- "Life.Exp"
View(state77)
model <- lm(Life.Exp ~ ., data=state77) #the '.' means include 'all' the remaining variables
summary(model) #shows the summary of the MRLM
model2 <- update(model, . ~ . -Income -Illiteracy -Area) #the '.' means 'same as in original model'
summary(model2)
confint(model2, level=0.95)
predict(model2,data.frame(HS.Grad=55,Murder=8))
predict(model2,data.frame(HS.Grad=55,Murder=8,Population=3000))
names(state77)[6] <- "HS.Grad"
predict(model2,data.frame(HS.Grad=55,Murder=8,Population=3000))
model2 <- update(model, . ~ . -Income -Illiteracy -Area) #the '.' means 'same as in original model'
predict(model2,data.frame(HS.Grad=55,Murder=8,Population=3000))
model2 <- update(model, . ~ . -Income -Illiteracy -Area) #the '.' means 'same as in original model'
summary(model2)
#List confidence intervals for second model
confint(model2, level=0.95)
model <- lm(Life.Exp ~ ., data=state77) #the '.' means include 'all' the remaining variables
model2 <- update(model, . ~ . -Income -Illiteracy -Area) #the '.' means 'same as in original model'
confint(model2, level=0.95)
predict(model2,data.frame(HS.Grad=55,Murder=8,Population=3000))
predict(model2,data.frame(HS.Grad=55,Murder=8,Population=3000,Frost=90))
library(rgl)
plot(model2)
plot(model,which=4)
plot(model2,which=4)
library(car)
install.packages("car")
library(car)
influencePlot(model2, main="Influence Plot")
pairs(~ Life.Exp + HS.Grad + Murder + Frost, data=state77, gap=0)
model3 <- lm(Life.Exp ~ HS.Grad + Murder, data=state77)
summary(model3)
plot(cars)
summary(cars)
boxplot(cars$speed)
boxplot(cars$speed, col="red")
boxplot(cars$speed, col="red", main="Boxplot of Speed")
install.packages("zoo")
install.packages("forecast")
install.packages(c("choroplethrAdmin1", "cluster", "curl", "DBI", "ggplot2", "ggraph", "jsonlite", "lattice", "Matrix", "mclust", "mgcv", "mvtnorm", "nlme", "pbapply", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rgl", "shiny", "stringi", "survival", "tibble", "units", "viridis", "viridisLite", "XML", "xml2"))
install.packages(c("choroplethrAdmin1", "cluster", "curl", "DBI", "ggplot2", "ggraph", "jsonlite", "lattice", "Matrix", "mclust", "mgcv", "mvtnorm", "nlme", "pbapply", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rgl", "shiny", "stringi", "survival", "tibble", "units", "viridis", "viridisLite", "XML", "xml2"))
install.packages(c("choroplethrAdmin1", "cluster", "curl", "DBI", "ggplot2", "ggraph", "jsonlite", "lattice", "Matrix", "mclust", "mgcv", "mvtnorm", "nlme", "pbapply", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rgl", "shiny", "stringi", "survival", "tibble", "units", "viridis", "viridisLite", "XML", "xml2"))
install.packages(c("choroplethrAdmin1", "cluster", "curl", "DBI", "ggplot2", "ggraph", "jsonlite", "lattice", "Matrix", "mclust", "mgcv", "mvtnorm", "nlme", "pbapply", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rgl", "shiny", "stringi", "survival", "tibble", "units", "viridis", "viridisLite", "XML", "xml2"))
install.packages("caret")
install.packages("caretEnsemble")
setwd('//Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 5/data')
library("neuralnet")
setwd('//Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 5/data')
library("neuralnet")
dataset <- read.csv("creditset.csv")
head(dataset)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
print(creditnet)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
#print(creditnet)
plot(creditnet, rep = "best")
#weight from models
creditnet$weights
creditnet$result.matrix
#results (notice in probabilities)
creditnet$net.result
## test the resulting output
temp_test <- subset(testset, select = c("LTI", "age"))
#compute the test results through the ANN model
creditnet.results <- compute(creditnet, temp_test)
#Make a table to predictions and actuals
results <- data.frame(actual = testset$default10yr,
prediction = creditnet.results$net.result)
print(results)
#Round predictions to make easier to read
results$prediction <- round(results$prediction)
#See partial results
results[100:115, ]
#See all results
print(results)
print(creditnet.results)
#USing Gmodels to create a confusion matrix
library(gmodels)
CrossTable(results$actual, results$prediction)
head(dataset)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
setwd('//Users/mpgartland/Documents/Courses/Predictive Models/Pred_Models_git/Week 5/data')
library("neuralnet")
dataset <- read.csv("creditset.csv")
head(dataset)
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
#print(creditnet)
plot(creditnet, rep = "best")
## extract a set to train the NN @ 65%
trainset <- dataset[1:1300, ]
## select the test set
testset <- dataset[1301:2000, ]
#NN nodel with one hiddeD layer and 4 nodes, resilient backprop
creditnet <- neuralnet(default10yr ~ LTI +age, trainset, hidden = 4, lifesign = "minimal",
linear.output = FALSE, threshold = 0.1,algorithm = "rprop+")
#print(creditnet)
